{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Getting started with Caffe\n",
    "\n",
    "This class was created by Allison Gray and Jon Barker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following timer counts down to a five minute warning before the lab instance shuts down.  You should get a pop up at the five minute warning reminding you to save your work!  If you are about to run out of time, please see the [Post-Lab](#Post-Lab-Summary) section for saving this lab to view offline later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe id=\"timer\" src=\"timer/timer.html\" width=\"100%\" height=\"120px\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Before we begin, let's verify [WebSockets](http://en.wikipedia.org/wiki/WebSocket) are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell.  If not, please consult the [Self-paced Lab Troubleshooting FAQ](https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting) to debug the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer should be three: 3\n"
     ]
    }
   ],
   "source": [
    "print \"The answer should be three: \" + str(1+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the cell below to display information about the GPUs running on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 15 19:16:14 2016       \r\n",
      "+------------------------------------------------------+                       \r\n",
      "| NVIDIA-SMI 346.46     Driver Version: 346.46         |                       \r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GRID K520           On   | 0000:00:03.0     Off |                  N/A |\r\n",
      "| N/A   30C    P8    18W / 125W |     10MiB /  4095MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Introduction\n",
    "\n",
    "[Caffe](http://caffe.berkeleyvision.org/) is a deep learning framework developed by the Berkely Vision and Learning Center (BVLC) and community contributors.  Caffe is released under the BSD 2-Clause license.  Caffe emphasizes easy application of deep learning. All neural networks and optimization parameters are defined by configuration files without any hard-coding and Caffe offers a command line interface as well as scripting interfaces in Python and MATLAB.  Caffe is fast due it's C++ and CUDA foundation, but the code is extensible fostering active development.  There is a large open-source community contributing many significant changes and state-of-the-art features back into Caffe.  Neural networks trained using Caffe are also saved into a well-defined binary format that makes them easy to share - in fact, there is a model zoo hosted [here](https://github.com/BVLC/caffe/wiki/Model-Zoo) where you can download cutting edge pre-trained neural networks.\n",
    "\n",
    "The objectives of this class are to learn how to complete the following tasks in Caffe:\n",
    "\n",
    "1. Build and train a convolutional neural network (CNN) for classifying images.\n",
    "2. Evaluate the classification performance of a trained CNN under different training parameter configurations.\n",
    "3. Modify the network configuration to improve classification performance.\n",
    "3. Visualize the features that a trained network has learned.\n",
    "4. Classify new test images using a trained network.\n",
    "\n",
    "This is an introductory class and is part of NVIDIA's five class Introduction to Deep Learning course.  It is assumed that you have completed the previous modules \"Introduction to Deep Learning\" and \"Getting Started with DIGITS interactive training system for image classification\" before starting this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Training and Classifying with Caffe\n",
    "\n",
    "You are provided with a subset of the [ImageNet](http://www.image-net.org/) dataset.  The images are from two different categories, cats and dogs.  Below are sample images from both categories.  The cats category includes domestic cats as well as large breeds like lions and tigers.  The dog category is comprised of domestic dogs including pugs, basenji and great pyrenees.  There are approximately 13,000 images in total.\n",
    "\n",
    "![](files/src/cat1.png)\n",
    "![](files/src/cat2.png)\n",
    "![](files/src/dog1.png)\n",
    "![](files/src/dog2.png)\n",
    "\n",
    "In this class we will be creating and training a deep neural network in Caffe that can accurately classify images from these two categories, i.e. can label an image of a dog as \"dog\" and an image of a cat as \"cat\".\n",
    "\n",
    "##Task 1 - Creating a Database and Mean Image\n",
    "\n",
    "Before we train a neural network using Caffe we will move the training and validation images into a database.  The database allows Caffe to efficiently iterate over the image data during training.  The training and validation datasets are independent subsets of the original image dataset.  We will train the network using the training dataset and then test the networks performance using the validation dataset; that way we can be sure that the network performs well for images that it has never been trained on.\n",
    "\n",
    "To minimize the training time during this class we have resized all of the images to 32x32 pixels for you.  The image files can be located anywhere on the filesystem.  Caffe knows which images belong to the training and validation sets and which class each image belongs to by referring to text files `train.txt` and `val.txt`.  These files simply list the relative filename of each image tab seperated from a natural number representing the class the image belongs to.  For example, `train.txt` contains the following rows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cat/cat_0_32.jpg 0\n",
    "cat/cat_1000_32.jpg 0\n",
    "dog/dog_9990_32.jpg 1\n",
    "dog/dog_9991_32.jpg 1\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a mean image from the training data. This is the image obtained by taking the mean value of each pixel across all of the training dataset images.  We do this so that we can extract that mean image from each training and validation image before it is fed into the neural network.  This is an important pre-processing step for achieving fast and effective training.  It has the effect of removing the average brightness (intensity) of each point in the image so that the network learns about image content rather than illumination conditions.\n",
    "\n",
    "We complete each of these tasks using command line tools that come with Caffe.  A number of useful utilities for data pre-processing, network training and network deployment can be found in the Caffe installation folder in `$CAFFE_ROOT/build/tools`\n",
    "\n",
    "Execute the cell below to create a mean image of the training data. (_Note_: you can ignore the \"Failed to initialize libdc1394\" warning messages in the output)\n",
    "\n",
    "You will know the lab is processing when you see a solid circle in the top-right of the window that looks like this: ![](jupyter_executing.png)\n",
    "Otherwise, when it is idle, you will see the following: ![](jupyter_idle.png)\n",
    "If you ever feel like a cell has run for to long, you can stop it with the stop button in the toolbar.\n",
    "For troubleshooting, please see [Self-paced Lab Troubleshooting FAQ](https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting) to debug the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0115 19:21:03.898493  3150 convert_imageset.cpp:143] Processed 1000 files.\n",
      "E0115 19:21:04.405110  3150 convert_imageset.cpp:143] Processed 2000 files.\n",
      "E0115 19:21:04.887454  3150 convert_imageset.cpp:143] Processed 3000 files.\n",
      "E0115 19:21:05.342878  3150 convert_imageset.cpp:143] Processed 4000 files.\n",
      "E0115 19:21:05.885934  3150 convert_imageset.cpp:143] Processed 5000 files.\n",
      "E0115 19:21:06.512353  3150 convert_imageset.cpp:143] Processed 6000 files.\n",
      "E0115 19:21:07.526595  3150 convert_imageset.cpp:143] Processed 7000 files.\n",
      "E0115 19:21:08.033902  3150 convert_imageset.cpp:143] Processed 8000 files.\n",
      "E0115 19:21:08.628804  3150 convert_imageset.cpp:143] Processed 9000 files.\n",
      "E0115 19:21:09.163836  3150 convert_imageset.cpp:143] Processed 10000 files.\n",
      "E0115 19:21:10.088855  3150 convert_imageset.cpp:143] Processed 11000 files.\n",
      "E0115 19:21:11.040606  3150 convert_imageset.cpp:143] Processed 12000 files.\n",
      "E0115 19:21:11.468827  3150 convert_imageset.cpp:149] Processed 12904 files.\n",
      "E0115 19:21:12.705242  3162 convert_imageset.cpp:143] Processed 1000 files.\n",
      "E0115 19:21:12.862079  3162 convert_imageset.cpp:149] Processed 1138 files.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf train_lmdb val_lmdb\n",
    "\n",
    "#Setup environment variables\n",
    "TOOLS=/home/ubuntu/caffe/build/tools\n",
    "TRAIN_DATA_ROOT=/home/ubuntu/data/dog_cat/dog_cat_32/train/\n",
    "VAL_DATA_ROOT=/home/ubuntu/data/dog_cat/dog_cat_32/val/\n",
    "\n",
    "#Create the training database\n",
    "$TOOLS/convert_imageset \\\n",
    "--shuffle \\\n",
    "$TRAIN_DATA_ROOT \\\n",
    "$TRAIN_DATA_ROOT/train.txt \\\n",
    "train_lmdb\n",
    "\n",
    "#Create the validation database\n",
    "$TOOLS/convert_imageset \\\n",
    "--shuffle \\\n",
    "$VAL_DATA_ROOT \\\n",
    "$VAL_DATA_ROOT/val.txt \\\n",
    "val_lmdb\n",
    "\n",
    "#Create the mean image database\n",
    "$TOOLS/compute_image_mean train_lmdb mean.binaryproto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see what the mean image looks like. Strangely, it looks a little like a mouse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD9CAYAAACY9xrCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfV2sbddV3pj3+NI4dmNkktiWfWVjiwceANuVEqQkBaQU\nBSGF8gKKQAk0VDy0FFHUJulD+XsoRCJC8BCVkiAnlD+BSEEVP04EJpAfmtROAgkkEbngEP8ExaG2\noqrxPbMPZ8+Tcb7zfWOMufY+e5/L